answer:-
1. What Are The Key Features Of NodeJs?
1. Asynchronous and Non-blocking I/O
  - Event-Driven Architecture:- Node.js uses an event-driven, non-blocking I/O model. This means operations like reading from a file or making a network request do not block the execution of other operations.
  - Callbacks and Promises:- It uses callbacks and promises to handle asynchronous operations, allowing other code to run while waiting for tasks to complete.

exam:-
function fetchData() {
    return new Promise((resolve, reject) => {
        setTimeout(() => {
            resolve('Data fetched');
        }, 2000);
    });
}

console.log('Task 1');
fetchData().then((data) => {
    console.log("Task 2"); // This runs after 2 seconds
});  
console.log('Task 3');

2. Single-Threaded with Event Loop
Single-Threaded Model: Node.js operates on a single thread using the event loop to handle multiple connections concurrently. This allows it to manage thousands of connections efficiently without creating a new thread for each connection.
Event Loop: The event loop is responsible for managing and dispatching events and callbacks, handling asynchronous operations.

3. High Performance
V8 Engine: Node.js uses the V8 JavaScript engine, developed by Google for Chrome, which compiles JavaScript to native machine code for fast execution.
Optimized for I/O-bound Applications: Its asynchronous model is particularly well-suited for applications that involve a lot of I/O operations, such as web servers and real-time applications.

4. Scalability
- Cluster Module: Node.js can leverage multiple CPU cores by using the cluster module, 
  which allows it to create child processes that share the same server port.
- Load Balancing: The cluster module helps in load balancing across multiple instances of a Node.js application, enhancing scalability.

exam:-
const cluster = require('cluster');
const http = require('http');
const numCPUs = require('os').cpus().length;
if (cluster.isMaster) {
    for (let i = 0; i < numCPUs; i++) {
        cluster.fork();
    }
    cluster.on('exit', (worker, code, signal) => {
        console.log(`Worker ${worker.process.pid} died`);
    });
} else {
    http.createServer((req, res) => {
        res.writeHead(200);
        res.end('Hello World\n');
    }).listen(8000);
}

5. NPM (Node Package Manager)
Package Management: Node.js comes with npm, a robust package manager that allows you to install, share, and manage dependencies and libraries for your projects.
Large Ecosystem: The npm registry hosts a vast number of packages, facilitating the integration of third-party libraries and tools.

6. Cross-Platform
Compatibility: Node.js is cross-platform and runs on major operating systems including Windows, macOS, and Linux. This makes it a versatile choice for development.

7. Built-in Modules
Core Modules: Node.js includes a variety of built-in modules, such as http, fs (file system), path, os, and url, that provide essential functionalities and reduce the need for external libraries.

8. Real-time Capabilities
WebSocket Support: Node.js is commonly used to build real-time applications, such as chat applications and live updates, thanks to its support for WebSockets and libraries like socket.io.

9. Microservices Friendly
Modular Architecture: Node.js is often used in microservices architectures due to its lightweight and modular nature, which aligns well with the microservices approach of breaking down applications into smaller, independently deployable services.

10. Community and Support
Active Community: Node.js has a large and active community that contributes to its ecosystem, provides support, and maintains a wealth of resources, tutorials, and documentation.


2.event loop?  How does Node.js work? its a part of libuv
A Node.js application creates a single thread on its invocation. Whenever Node.js receives a request, it first completes its processing before moving on to the next request.
Node.js works asynchronously by using the event loop and callback functions, to handle multiple requests coming in parallel. An Event Loop is a functionality which handles and processes all your external events and just converts them to a callback function. It invokes all the event handlers at a proper time. Thus, lots of work is done on the back-end, while processing a single request, so that the new incoming request doesn't have to wait if the processing is not complete.
While processing a request, Node.js attaches a callback function to it and moves it to the back-end. Now, whenever its response is ready, an event is called which triggers the associated callback function to send this response.



3 What are the core modules of Node.js?
Node.js has a set of core modules that are part of the platform and come with the Node.js installation. These modules can be loaded into the program by using the require function.
some of the important core modules in Node.js.
1. http      
const http = require('http');
const server = http.createServer((req, res) => {
    res.writeHead(200, {'Content-Type': 'text/plain'});
    res.end('Hello World\n');
});
server.listen(3000, () => {
    console.log('Server running at http://localhost:3000/');
});


2. fs (File System)       
const fs = require('fs');
fs.readFile('example.txt', 'utf8', (err, data) => {
    if (err) throw err;
    console.log(data);
});

3. path
const path = require('path');
const filePath = path.join(__dirname, 'example.txt');
console.log(filePath);

4. os
const os = require('os');
console.log('Platform:', os.platform());
console.log('CPU Architecture:', os.arch());
console.log('Free Memory:', os.freemem());

5. url
const url = require('url');
const myURL = new URL('https://example.com:8000/pathname/?search=test#hash');
console.log('Hostname:', myURL.hostname);
console.log('Port:', myURL.port);
console.log('Search Params:', myURL.searchParams.get('search'));

6. utils
const util = require('util');
const formatString = util.format('%s is %d years old', 'Alice', 30);
console.log(formatString);

7. events
const EventEmitter = require('events');
const eventEmitter = new EventEmitter();
eventEmitter.on('event', () => {
    console.log('Event occurred!');
});

8.stream
const fs = require('fs');
const readableStream = fs.createReadStream('example.txt');
readableStream.on('data', (chunk) => {
    console.log('Received chunk:', chunk.toString());
});
eventEmitter.emit('event');

9. child_process
const { exec } = require('child_process');
exec('ls', (err, stdout, stderr) => {
    if (err) {
        console.error('Error:', err);
        return;
    }
    console.log('Output:', stdout);
});

10.Cluster
Cluster	This module is used by Node.js to take advantage of multi-core systems, so that it can handle more load. It can be accessed with require('cluster').



4 What are streams in Nodejs Explain the different types of streams present in Nodejs?
Streams are objects that allow the reading of data from the source and writing of data to the destination as a continuous process.
There are four types of streams.
facilitate the reading operation.
facilitate the writing operations
facilitate both read and write operations.
Duplex stream that performs computations based on the available input.

1. Reading from a streams:
const fs = require("fs");
let data = "";

// Create a readable stream
const readerStream = fs.createReadStream("file.txt");

// Set the encoding to be utf8.
readerStream.setEncoding("UTF8");

// Handle stream events --> data, end, and error
readerStream.on("data", function (chunk) {
  data += chunk;
});

readerStream.on("end", function () {
  console.log(data);
});

readerStream.on("error", function (err) {
  console.log(err.stack);
});



2. Writing to a Stream:
const fs = require("fs");
const data = "File writing to a stream example";

// Create a writable stream
const writerStream = fs.createWriteStream("file.txt");

// Write the data to stream with encoding to be utf8
writerStream.write(data, "UTF8");

// Mark the end of file
writerStream.end();

// Handle stream events --> finish, and error
writerStream.on("finish", function () {
  console.log("Write completed.");
});

writerStream.on("error", function (err) {
  console.log(err.stack);
});



3. Piping the Streams:
Piping is a mechanism where we provide the output of one stream as the input to another stream. It is normally used to get data from one stream and to pass the output of that stream to another stream. There is no limit on piping operations.

const fs = require("fs");
// Create a readable stream
const readerStream = fs.createReadStream('input.txt');

// Create a writable stream
const writerStream = fs.createWriteStream('output.txt');

// Pipe the read and write operations
// read input.txt and write data to output.txt
readerStream.pipe(writerStream);


4. Chaining the Streams:
Chaining is a mechanism to connect the output of one stream to another stream and create a chain of multiple stream operations. It is normally used with piping operations.
const fs = require("fs");
const zlib = require('zlib');
// Compress the file input.txt to input.txt.gz
fs.createReadStream('input.txt')
   .pipe(zlib.createGzip())
   .pipe(fs.createWriteStream('input.txt.gz'));
console.log("File Compressed.");

How to handle large data in Node.js?
The Node.js stream feature makes it possible to process large data continuously in smaller chunks without keeping it all in memory. 
One benefit of using streams is that it saves time, 
since you don't have to wait for all the data to load before you start processing. This also makes the process less memory-intensive.

Some of the use cases of Node.js streams include:
Reading a file that's larger than the free memory space, because it's broken into smaller chunks and processed by streams. 
For example, a browser processes videos from streaming platforms like Netflix in small chunks, making it possible to watch videos immediately without having to download them all at once.
Reading large log files and writing selected parts directly to another file without downloading the source file. For example, 
you can go through traffic records spanning multiple years to extract the busiest day in a given year and save that data to a new file.


const fs = require('fs').promises;
// Reading a file using Promises
fs.readFile('example.txt', 'utf8')
    .then((data) => {
        console.log(data); // Output: Content of example.txt
    })
    .catch((err) => {
        console.error("Error reading file:", err);
    });



6 How can you avoid callback hells?
There are lots of ways to solve the issue of callback hells:
1.modularization: break callbacks into independent functions,
2.use a control flow library, like async await.
3.use generators with Promises,



7 What Is EventEmitter In NodeJs?
Events module in Node.js allows us to create and handle custom events. The Event module contains “EventEmitter” class 
which can be used to raise and handle custom events. It is accessible via the following code.

const EventEmitter = require('events');
// Create a new instance of EventEmitter
const eventEmitter = new EventEmitter();

// Register a listener for the 'greet' event
eventEmitter.on('greet', (name) => {
    console.log(`Hello, ${name}!`);   // Hello Alice
});

// Emit the 'greet' event and pass a parameter to the listener
eventEmitter.emit('greet', 'Alice');



9 Which are the areas where it is suitable to use NodeJS?
I/O bound Applications
Data Streaming Applications
Data Intensive Real-time Applications (DIRT)
JSON APIs based Applications
Single Page Applications


10 What are the tasks that a middleware can do?
Middleware functions can perform the following tasks:
A middleware is a simple function that has the ability to handle incoming requests and outbound response objects. Middleware is used primarily for the following tasks:

Execute any code.
Make changes to the request and the response objects.
End the request-response cycle.
Call the next middleware function in the stack.


11 What are the different types of middleware?
  // Application-level middleware

    const express = require('express');
    const app = express();

    // Application-level middleware
    app.use((req, res, next) => {
        console.log('Time:', Date.now());
        next(); // Pass control to the next middleware
    });

    app.get('/', (req, res) => {
        res.send('Home Page');
    });

    app.listen(3000, () => {
      console.log('Server is running on port 3000');
    });

12. Router-level middleware
    const express = require('express');
  const app = express();
  const router = express.Router();

  // Router-level middleware
  router.use((req, res, next) => {
      console.log('Router-level middleware');
      next();
  });

  router.get('/user/:id', (req, res) => {
      res.send(`User ID: ${req.params.id}`);
  });

  app.use('/api', router);


Error-handling middleware
  const express = require('express');
  const app = express();

  app.get('/', (req, res) => {
      throw new Error('Something went wrong!');
  });

  // Error-handling middleware
  app.use((err, req, res, next) => {
      console.error(err.stack);
      res.status(500).send('Something broke!');
  });


Built-in middleware:-
  const express = require('express');
  const app = express();

  // Built-in middleware
  app.use(express.json()); // Parses incoming JSON requests
  app.use(express.urlencoded({ extended: true })); // Parses URL-encoded bodies

  app.post('/data', (req, res) => {
      res.send(req.body);
  });


  Third-party middleware:-
  const express = require('express');
  const morgan = require('morgan');
  const app = express();

  // Third-party middleware
  app.use(morgan('dev')); // Logs HTTP requests

  app.get('/', (req, res) => {
      res.send('Home Page');
  });


12 How can we read or write files in node js?
The fs module provides an API for interacting with the file system in a manner closely modeled around standard POSIX functions. To use this module:

const fs = require('fs');
fs.readFile(file, [data, options], callback)
fs.writeFile(file, [data, options], callback)



13 Explain libuv?
Libuv is a multi-platform support library of Node.js which majorly is used for asynchronous I/O. It was primarily developed for Node.js, 
with time it is popularly practiced with other systems like as Luvit, pyuv, Julia, etc. Libuv is basically an abstraction around 
libev/ IOCP depending on the platform, providing users an API based on libev. A few of the important features of libuv are:

Full-featured event loop backend
File system events
Asynchronous file & file system operations
Asynchronous TCP & UDP sockets
Child processes

console.log("Start");
setTimeout(function () {
  console.log("Timeout callback");
}, 2000);

fs.readFile("example.txt", "utf8", function (err, data) {
  console.log("File Read Callback");
});
console.log("End");



14. What is the difference between spawn and fork methods in Node.js?
The spawn() function is used to create a new process and launch it using the command line. What it does is that it creates a node module on the processor. Node.js invokes this method when the child processes return data.

The following is the syntax for the spawn() method:
child_process.spawn(command[, args][, options])
Coming to the fork() method, it can be considered as an instance of the already existing spawn() method. Spawning ensures that there is more than one active worker node to handle tasks at any given point in time.

The following is the syntax for the fork() method:
child_process.fork(modulePath[, args][, options])



16 How can we take advantage of multi-core system in Nodejs as nodejs works on single thread?
We can use node js cluster to use multicores in the hardware,The cluster module allows easy creation of child processes that all share server ports


18 Explain chaining in Nodejs?
Chaining is a mechanism whereby the output of one stream is connected to another stream creating a chain of multiple stream operations.


19 Explain REPL In NodeJs?
The REPL stands for “Read Eval Print Loop”. It is a simple program that accepts the commands, evaluates them, and finally prints the results. 
REPL provides an environment similar to that of Unix/Linux shell or a window console, in which we can enter the command and the system, in turn, responds with the output. REPL performs the following tasks.

READ - It Reads the input from the user, parses it into JavaScript data structure and then stores it in the memory.
EVAL - It Executes the data structure.
PRINT - It Prints the result obtained after evaluating the command.
LOOP - It Loops the above command until the user presses Ctrl+C two times.

repl:- read-eval-print-loop
calculation karna evulate karna cmd shell par


20 What are buffer objects in nodejs?
In Node.js, Buffer objects are used to represent binary data in the form of a sequence of bytes. Many Node.js APIs, for example streams and file system operations, 
support Buffers, as interactions with the operating system or other processes generally always happen in terms of binary data

buffer=
its a temporary memory location in nodejs while creating file nodejs need some memory location.


21 How does Nodejs handle the child threads?
In general, Node.js is a single threaded process and doesn’t expose the child threads or thread management methods. But you can still make use of the child threads 
using spawn() for some specific asynchronous I/O tasks which execute in the background and don’t usually execute any JS code or hinder with the main event loop in the application. 
If you still want to use the threading concept in your application you have to include a module called ChildProcess explicitly.


22 Explain the purpose of module exports?
A module in Node.js is used to encapsulate all the related codes into a single unit of code which can be interpreted by shifting all related functions into a single file


23 NPM stands for Node Package Manager. It provides following two main functionalities.
It works as an Online repository for node.js packages/modules which are present at <nodejs.org>.
It works as Command line utility to install packages, do version management and dependency management of Node.js packages. NPM comes bundled along with Node.js installable. We can verify its version using the following command-


24. What is load balancer and how it works?
A load balancer is a process that takes in HTTP requests and forwards these HTTP requests to one of a collection of servers. 
Load balancers are usually used for performance purposes: if a server needs to do a lot of work for each request, one server might not be enough, but 2 servers alternating handling incoming requests might.
1. Using cluster module:
cluster:-
server ka copy
traffic ko handle



25 How does the cluster module work in Node.js?
The cluster module provides a way of creating child processes that runs simultaneously and share the same server port.
Node.js runs single threaded programming, which is very memory efficient, but to take advantage of computers multi-core systems, 
the Cluster module allows you to easily create child processes that each runs on their own single thread, to handle the load.

Load Balancer Example:
/**
 * Cluster Module
 */
const cluster = require("cluster");

if (cluster.isMaster) {
  console.log(`Master process is running...`);
  cluster.fork();
} else {
  console.log(`Worker process started running`);
}

Output:
Master process is running...
Worker process started running

others
Informational responses (100 – 199)
Successful responses (200 – 299)
Redirection messages (300 – 399)
Client error responses (400 – 499)
Server error responses (500 – 599)


different engine in nodejs
chrome v8
safari chakra
firefox  spiderman



// const app=express();
// const {middlewarename}= "/index"

// let newFun= async ()=>{
//     let userdata= await userInfo()
//     console.log("userdata", userdata)
//     // next()
//     console.log("someting")
// }

// var userInfo=()=>{
//     setTimeout(() => {
//         console.log("api called")
// }, 5000);
// }

// let newdata= newFun()
// console.log("newdata", newdata)



event driven architecture  (mouseEvent)   
event EventEmitter   (event emit)
event listener 
event handlers


setTimeout
setInterver
setimmediate